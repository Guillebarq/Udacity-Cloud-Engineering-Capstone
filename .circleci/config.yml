version: 2.1

commands:
  install_awscli:
    description: Install AWS CLI v2
    steps:
      - run:
          name: Install AWS CLI v2
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
  install_ansible:
    description: Install Ansible
    steps:
      - run:
          name: Install Ansible
          command: |
            sudo apt update
            sudo apt install software-properties-common -y
            sudo add-apt-repository --yes --update ppa:ansible/ansible
            sudo apt install ansible -y
  install_wget:
    description: Install wget
    steps:
      - run:
          name: Install wget
          command: |
            apt-get update
            apt-get install -y wget
            rm -rf /var/lib/apt/lists/*
  install_make:
    description: Install make
    steps:
      - run:
          name: Install make
          command: |
            apt-get update
            apt-get install make
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      Workflow_ID:
        type: string
        default: ${CIRCLE_WORKFLOW_ID:0:7}
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name ${ENVIRONMENT_NAME}-kube-network-<< parameters.Workflow_ID >>
            aws cloudformation delete-stack --stack-name ${ENVIRONMENT_NAME}-cluster-<< parameters.Workflow_ID >>
            aws cloudformation delete-stack --stack-name ${ENVIRONMENT_NAME}-kube-node-group-<< parameters.Workflow_ID >>

  save_workflow_id:
    description: Save workflow ID on kvdb
    steps:
      - run:
          name: Save Old Workflow ID to kvdb.io
          command: |
            export OLD_WORKFLOW_ID=$(aws cloudformation \
                      list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
                      --no-paginate --output text)
            echo "Old Wokflow ID: $OLD_WORKFLOW_ID"
            curl https://kvdb.io/LBcnJjxskczGJWNszqSJsH/old_workflow_id -d "${OLD_WORKFLOW_ID}"

jobs:
  build-app:
    docker:
      - image: python:3.9.18-slim-bullseye
    steps:
      - checkout
      - install_make
      - install_wget
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            - v1-dependencies-
      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
      - run:
          name: run lint
          command: |
            . venv/bin/activate
            make lint
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}

  upload-docker:
    docker:
      - image: circleci/golang:1.15
    working_directory: ~/repo
    steps:
      - checkout
      - setup_remote_docker:
          version: 20.10.14
      - run:
          name: Build docker container
          command: |
            docker build --tag=$DOCKER_IMAGE_NAME .
            docker image ls
      - run:
          name: Upload Docker to Dockerhub
          command: |
            echo "Docker Image: $DOCKER_IMAGE_NAME"
            docker login -u="$DOCKER_USERNAME" -p="$DOCKER_PASSWORD"
            docker tag $DOCKER_IMAGE_NAME $DOCKER_USERNAME/$DOCKER_IMAGE_NAME:${CIRCLE_WORKFLOW_ID:0:7}
            docker push $DOCKER_USERNAME/$DOCKER_IMAGE_NAME:${CIRCLE_WORKFLOW_ID:0:7}

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    parameters:
      StackNetworkName:
        type: string
        default: ${ENVIRONMENT_NAME}-kube-network
      StackNodeGroupName:
        type: string
        default: ${ENVIRONMENT_NAME}-node-group
      StackClusterName:
        type: string
        default: ${ENVIRONMENT_NAME}-cluster
      StackKubeManager:
        type: string
        default: ${ENVIRONMENT_NAME}-kube-manager
    steps:
      - checkout
      - run:
          name: Deploy Kubernetes Network
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/network-infra.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name <<parameters.StackNetworkName>> \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/network-parameters.json
      - run:
          name: Deploy EKS Kube Cluster
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/kubernetes.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name <<parameters.StackClusterName>> \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/kubernetes-parameters.json \
              --capabilities CAPABILITY_NAMED_IAM
          no_output_timeout: 20m
      - run:
          name: Create Node Group
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/node-group.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name <<parameters.StackNodeGroupName>> \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/node-group-parameters.json \
              --capabilities CAPABILITY_NAMED_IAM
      # - run:
      #     name: Destroy Stacks and Wait
      #     when: on_fail
      #     command: |
      #       if aws cloudformation describe-stacks --stack-name <<parameters.StackKubeManager>>; then
      #         aws cloudformation delete-stack --stack-name <<parameters.StackKubeManager>>
      #       fi
      #       if aws cloudformation describe-stacks --stack-name <<parameters.StackNodeGroupName>>; then
      #         aws cloudformation delete-stack --stack-name <<parameters.StackNodeGroupName>>
      #         aws cloudformation wait stack-delete-complete --stack-name <<parameters.StackNodeGroupName>>
      #       fi
      #       if aws cloudformation describe-stacks --stack-name <<parameters.StackClusterName>>; then
      #         aws cloudformation delete-stack --stack-name <<parameters.StackClusterName>>
      #         aws cloudformation wait stack-delete-complete --stack-name <<parameters.StackClusterName>>
      #       fi
      #       if aws cloudformation describe-stacks --stack-name <<parameters.StackNetworkName>>; then
      #         aws cloudformation delete-stack --stack-name <<parameters.StackNetworkName>>
      #         aws cloudformation wait stack-delete-complete --stack-name <<parameters.StackNetworkName>>
      #       fi
            
      - save_workflow_id


  deploy-kube-manager:
    docker:
      - image: amazon/aws-cli
    parameters:
      StackKubeManager:
        type: string
        default: ${ENVIRONMENT_NAME}-kube-manager
    steps:
      - checkout
      - run:
          name: Install tar & gzip
          command: yum install -y tar gzip
      - run:
          name: Create kubernetes management EC2 Instance
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/kube-manager.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name <<parameters.StackKubeManager>> \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/kube-manager-parameters.json    

  configure-kube-manager:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - install_ansible
      - install_awscli
      - add_ssh_keys:
          fingerprints:
            - "eb:e7:c6:8f:ab:a7:17:d8:f8:d0:a9:95:28:b2:ba:ed"
      - run:
          name: Extract the IPs of the management instances for Ansible
          command: |
            echo [ec2] > ~/inventory.txt
            aws ec2 describe-instances \
              --region "${AWS_DEFAULT_REGION}" \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:Name,Values=${ENVIRONMENT_NAME}-kube-manager*" \
              --output text >> ~/inventory.txt
            cat ~/inventory.txt
      - run:
          name: Configure Kubernetes Management EC2
          command: |
            cat ~/inventory.txt
            cd ansible
            ansible-playbook -i ~/inventory.txt configure-management-server.yml
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt

  deploy-helm-charts:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - install_ansible
      - add_ssh_keys:
          fingerprints:
            - "eb:e7:c6:8f:ab:a7:17:d8:f8:d0:a9:95:28:b2:ba:ed"
      - attach_workspace:
          at: ~/
      - run:
          name: Deploy helm charts on cluster
          command: |
              cd ansible
              ansible-playbook -i ~/inventory.txt deploy-helm-charts.yml
      - run:
          name: Display the app's DNS name
          command: |
            cd ansible
            ansible-playbook -i ~/inventory.txt save-dns-name.yml
            cat /tmp/dns.txt
      - run:
          name: Uninstall Helm Charts
          when: on_fail
          command: |
            cd ansible
            ansible-playbook -i ~/inventory.txt helm-uninstall.yml

  cleanup:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - install_awscli
      - install_nodejs
      - run:
          name: Fetch old stack worklow ID and cleanup
          command: |
            ## Fetch the Old workflow ID
            export OLD_WORKFLOW_ID=$(curl --insecure https://kvdb.io/LBcnJjxskczGJWNszqSJsH/old_workflow_id)
            export STACKS=($(aws --region us-east-1 cloudformation list-stacks --query "StackSummaries[*].StackName" --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
            echo OLD_WORKFLOW_ID: "${OLD_WORKFLOW_ID}"
            echo CIRCLE_WORKFLOW_ID "$CIRCLE_WORKFLOW_ID"
            echo OLD_WORKFLOW_NUMBERs "${OLD_WORKFLOW_ID:10:16}""
            echo Stack names: "${STACKS[@]}"
            if [[ "${CIRCLE_WORKFLOW_ID:0:7}" != "${OLD_WORKFLOW_ID:0:7}" ]]
            then
              echo '----------------------------------Delete Confirmed------------------------------------'
              aws s3 rm "s3://${OLD_WORKFLOW_ID}" --recursive
              aws cloudformation delete-stack --stack-name "udapeople-backend-${OLD_WORKFLOW_ID:10:16}"
              aws cloudformation delete-stack --stack-name "udapeople-frontend-${OLD_WORKFLOW_ID:10:16}"
            else
              echo '------------------------------------Cannot Cleanup------------------------------------'
            fi

workflows:
  default:
    jobs:
      - build-app
      - upload-docker:
          requires: [build-app]
          filters:
            branches:
              only: [ main ]
      - deploy-infrastructure:
          filters:
            branches:
              only: [ main ]
      - deploy-kube-manager:
          requires: [deploy-infrastructure]
          filters:
            branches:
              only: [ main ]
      - configure-kube-manager: 
          requires: 
            - deploy-kube-manager
            - upload-docker
      - deploy-helm-charts:
            requires: [configure-kube-manager]
      # - save-workflow-id:
      #     requires: [configure-kube-manager]